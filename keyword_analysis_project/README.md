
# í‚¤ì›Œë“œ ë¶„ì„ í”„ë¡œì íŠ¸
> í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì‹¤í–‰(run) ë‹¨ìœ„ë¡œ ê´€ë¦¬í•˜ê³ , í‚¤ì›Œë“œÂ·í† í”½Â·ì—”í„°í‹°ë¥¼ ë¶„ì„í•´ HTML ëŒ€ì‹œë³´ë“œë¡œ ì¶œë ¥í•˜ëŠ” íŒŒì´í”„ë¼ì¸
---

## ğŸ“Œ ëª©ì°¨
- [0) TL;DR](#0-tldr)
- [1) ì£¼ìš” ê¸°ëŠ¥](#1-ì£¼ìš”-ê¸°ëŠ¥)
- [2) í´ë” êµ¬ì¡°](#2-í´ë”-êµ¬ì¡°)
- [3) ë¹ ë¥¸ ì‹¤í–‰ ë°©ë²•](#3-ë¹ ë¥¸-ì‹¤í–‰-ë°©ë²•)
- [4) ì„¤ì •íŒŒì¼](#4-ì„¤ì •íŒŒì¼)
- [5) íŒŒì´í”„ë¼ì¸ ë‹¨ê³„](#5-íŒŒì´í”„ë¼ì¸-ë‹¨ê³„--í˜„ì¬-vs-ë¯¸êµ¬í˜„)
- [6) ì¶œë ¥ë¬¼](#6-ì¶œë ¥ë¬¼)
- [7) ìš”êµ¬ ì‚¬í•­](#7-ìš”êµ¬-ì‚¬í•­)
- [8) ë¡œë“œë§µ](#8-ë¡œë“œë§µ)
- [9) ë¼ì´ì„ ìŠ¤](#9-ë¼ì´ì„ ìŠ¤)

---

## 0) TL;DR
- ğŸ—‚ï¸ **ìœ ì—°í•œ ë°ì´í„°ì…‹ ê´€ë¦¬**: `data/raw/{dataset_id}/`ì— snapshot ì €ì¥ (ê¸°ë³¸ê°’: `latest`)
- ğŸ“‚ **ì‹¤í–‰(run) ë‹¨ìœ„ ì¶œë ¥**: ì‹¤í–‰ ì‹œë§ˆë‹¤ `*/{run_id}`ì— ê²°ê³¼ ì €ì¥ (`{dataset_id}_{YYYYMMDDHHMMSS}`)
- âš™ï¸ **í˜„ì¬ ìƒíƒœ**: íŒŒì´í”„ë¼ì¸ì€ end-to-end ì‹¤í–‰ ê°€ëŠ¥. ì¼ë¶€ ë‹¨ê³„ëŠ” **placeholder ë¡œì§**ìœ¼ë¡œ êµ¬í˜„ â†’ ì¶”í›„ ì—…ê·¸ë ˆì´ë“œ ì˜ˆì •

---

## 1) ì£¼ìš” ê¸°ëŠ¥
-  Dataset / ë²„ì „ ê´€ë¦¬ (`latest` ë˜ëŠ” `--dataset_id` ì§€ì • ê°€ëŠ¥)
-  8ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ (ë¡œë“œ â†’ í† í°í™” â†’ í‚¤ì›Œë“œ â†’ ê³µë™ì¶œí˜„ â†’ í† í”½ â†’ NER â†’ ë¶„ë¥˜ â†’ ëŒ€ì‹œë³´ë“œ)
-  ì‹¤í–‰(run) ë‹¨ìœ„ë³„ ì¬í˜„ ê°€ëŠ¥í•œ ì¶œë ¥
-  ì—…ê·¸ë ˆì´ë“œ ì˜ˆì •: í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸°, TF-IDF, LDA/BERTopic, spaCy NER, ML ë¶„ë¥˜ê¸°, Plotly ëŒ€ì‹œë³´ë“œ



---

## 2) í´ë” êµ¬ì¡°

```markdown
keyword_analysis_project/
â”œâ”€ configs/
â”‚  â””â”€ config.yaml              # íŒŒì´í”„ë¼ì¸ ì„¤ì •
â”œâ”€ data/
â”‚  â”œâ”€ raw/                     # ì›ë³¸ ë°ì´í„°ì…‹ ìŠ¤ëƒ…ìƒ·
â”‚  â”‚  â””â”€ filtered_blog2.json
â”‚  â”œâ”€ interim/                 # ì¤‘ê°„ ì‚°ì¶œë¬¼ (run_id ë‹¨ìœ„)
â”‚  â”‚  â””â”€ {run_id}/
â”‚  â”‚     â”œâ”€ cleaned.csv
â”‚  â”‚     â””â”€ tokens.csv
â”‚  â””â”€ processed/               # ìµœì¢… ê°€ê³µ ì‚°ì¶œë¬¼ (run_id ë‹¨ìœ„)
â”‚     â””â”€ {run_id}/
â”‚        â”œâ”€ keywords_top.csv
â”‚        â”œâ”€ ngrams_edges.csv
â”‚        â”œâ”€ topics.json
â”‚        â”œâ”€ entities.csv
â”‚        â””â”€ layer_tags.csv
â”œâ”€ dicts/
â”‚  â”œâ”€ stopwords.txt
â”‚  â”œâ”€ synonyms.csv
â”‚  â”œâ”€ program_list.csv
â”‚  â”œâ”€ layer_rules.yml
â”‚  â””â”€ persona_rules.yml
â”œâ”€ logs/
â”‚  â””â”€ *.log
â”œâ”€ outputs/
â”‚  â”œâ”€ runs/
â”‚  â”‚  â””â”€ {run_id}/dashboard/
â”‚  â”‚     â””â”€ dash.html
â”‚  â””â”€ latest_run.json          # ìµœê·¼ ì‹¤í–‰ í¬ì¸í„°
src/
â”œâ”€ 01_load_clean.py
â”œâ”€ 02_tokenize.py              # í˜„ì¬: ê³µë°± ê¸°ë°˜ í† í°í™”
â”‚   â””â”€ 02_tokenize_korean.py   # planned: í˜•íƒœì†Œ ë¶„ì„ê¸° ê¸°ë°˜
â”œâ”€ 03_keywords_tfidf.py        # í˜„ì¬: ë¹ˆë„ ê¸°ë°˜ placeholder
â”‚   â””â”€ 03_keywords_tfidf_true.py   # planned: ì‹¤ì œ TF-IDF
â”œâ”€ 04_ngrams_cooc.py           # ì˜ë¯¸ë‹¨ìœ„ ê·¸ë£¹í™”
â”œâ”€ 05_topics.py                # í˜„ì¬: ì´ˆì„± ê·¸ë£¹ placeholder
â”‚   â”œâ”€ 05_topics_lda.py        # planned: LDA
â”‚   â””â”€ 05_topics_bertopic.py   # planned: BERTopic
â”œâ”€ 06_ner.py                   # í˜„ì¬: ë£° ê¸°ë°˜ í”„ë¡œê·¸ë¨ëª… ì¶”ì¶œ
â”‚   â””â”€ 06_ner_spacy_ko.py      # planned: spaCy KoELECTRA ê¸°ë°˜
â”œâ”€ 07_classify.py              # í˜„ì¬: ë£° ê¸°ë°˜ Layer ë¶„ë¥˜
â”‚   â””â”€ 07_classify_ml.py       # planned: ML ê¸°ë°˜ classifier
â”œâ”€ 08_dashboard.py             # í˜„ì¬: ê°„ë‹¨í•œ HTML ëŒ€ì‹œë³´ë“œ
â”‚   â””â”€ 08_dashboard_plotly.py  # planned: Plotly ì¸í„°ë™í‹°ë¸Œ
â”œâ”€ utils/
â”‚   â”œâ”€ config.py
â”‚   â”œâ”€ io.py
â”‚   â”œâ”€ log.py
â”‚   â””â”€ text.py
â”œâ”€ notebooks/
â”‚  â””â”€ EDA.ipynb                 # (planned)
â”œâ”€ requirements.txt
â”œâ”€ run_pipeline.py
â””â”€ README.md
```
```mermaid
flowchart LR

    A[run_pipeline.py] --> B[configs/config.yaml]
    B --> C[src<br>01_load_clean.py]

    subgraph src
     
      C --> D[src<br>02_tokenize.py<br>ê³µë°± ê¸°ë°˜ í† í°í™”]
      D --> E[src<br>03_keywords_tfidf.py<br>ë¹ˆë„ ê¸°ë°˜ placeholder]
      E --> F[src<br>04_ngrams_cooc.py<br>ì˜ë¯¸ë‹¨ìœ„ ê·¸ë£¹í™”]
      F --> G[src<br>05_topics.py<br>ì´ˆì„± ê·¸ë£¹ placeholder]
      G --> H[src<br>06_ner.py<br>ë£° ê¸°ë°˜ í”„ë¡œê·¸ë¨ëª… ì¶”ì¶œ]
      H --> I[src<br>07_classify.py<br>ë£° ê¸°ë°˜ Layer ë¶„ë¥˜]
      I --> J[src<br>08_dashboard.py<br>ê°„ë‹¨í•œ HTML ëŒ€ì‹œë³´ë“œ]
    end
    subgraph utils
        U1[src<br>utils<br>config.py]
        U2[src<br>utils<br>io.py]
        U3[src<br>utils<br>log.py]
        U4[src<br>utils<br>text.py]
    end

    A --> U1
    C --> U2
    D --> U4
    J --> U3
```

### ğŸ“‚ íŒŒì¼ë³„ ì—­í•  ì„¤ëª…

| **íŒŒì¼** | **ê¸°ëŠ¥ ì„¤ëª…** |
|----------|----------------|
| run_pipeline.py | íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰ ì‹œì‘ì . `configs/config.yaml`ì„ ì½ì–´ dataset_id, run_id, ì¶œë ¥ ê²½ë¡œ ë“±ì„ ì„¤ì •í•˜ê³ , ë‹¨ê³„ë³„ ìŠ¤í¬ë¦½íŠ¸(01~08)ë¥¼ ìˆœì°¨ ì‹¤í–‰í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—­í• . |
| src/01_load_clean.py | ì›ë³¸ JSON ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ í´ë¦¬ë‹(HTML íƒœê·¸ ì œê±°, íŠ¹ìˆ˜ë¬¸ì/ê³µë°± ì •ë¦¬ ë“±) í›„ `cleaned.csv`ë¥¼ ìƒì„±. |
| src/02_tokenize.py | í˜„ì¬ ë²„ì „ì€ ë‹¨ìˆœ ê³µë°± ê¸°ë°˜ í† í°í™”. stopwords(`dicts/stopwords.txt`) ì œê±°ì™€ synonyms(`dicts/synonyms.csv`) ì¹˜í™˜ì„ ì ìš©. ê²°ê³¼ëŠ” `tokens.csv`. |
| src/03_keywords_tfidf.py | í˜„ì¬ëŠ” ë¹ˆë„ ê¸°ë°˜ placeholderë¡œ í‚¤ì›Œë“œ ìƒìœ„ nê°œë¥¼ ì‚°ì¶œ. ê²°ê³¼ëŠ” `keywords_top.csv`. í–¥í›„ TF-IDF ê¸°ë°˜ìœ¼ë¡œ í™•ì¥ ì˜ˆì •. |
| src/04_ngrams_cooc.py | í† í° ë¦¬ìŠ¤íŠ¸ì—ì„œ n-gramê³¼ ê³µë™ì¶œí˜„(co-occurrence) ê´€ê³„ë¥¼ ê³„ì‚°. ê²°ê³¼ëŠ” `ngrams_edges.csv` (ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš© ì—£ì§€ ë¦¬ìŠ¤íŠ¸). |
| src/05_topics.py | í˜„ì¬ëŠ” ë‹¨ìˆœ placeholder (ì˜ˆ: ì´ˆì„± ê·¸ë£¹í™”). ê²°ê³¼ëŠ” `topics.json`. í–¥í›„ LDA/BERTopicìœ¼ë¡œ êµì²´ ì˜ˆì •. |
| src/06_ner.py | ë£° ê¸°ë°˜ NER(ê°œì²´ëª…ì¸ì‹, Named Entity Recognition). `dicts/program_list.csv`ì— ì •ì˜ëœ í”„ë¡œê·¸ë¨ëª…ì„ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œí•˜ì—¬ `entities.csv` ìƒì„±. |
| src/07_classify.py | í˜ë¥´ì†Œë‚˜ ë£° ê¸°ë°˜ ë¬¸ì„œ ë¶„ë¥˜. `dicts/layer_rules.yml`, `dicts/persona_rules.yml` ê·œì¹™ì„ ì´ìš©í•´ `layer_tags.csv` ìƒì„±. |
| src/08_dashboard.py | ë¶„ì„ ê²°ê³¼ë¥¼ ê°„ë‹¨í•œ ì •ì  HTML ëŒ€ì‹œë³´ë“œ(`dash.html`)ë¡œ ì¶œë ¥. í–¥í›„ Plotly ê¸°ë°˜ ì¸í„°ë™í‹°ë¸Œ ë²„ì „ìœ¼ë¡œ í™•ì¥ ì˜ˆì •. |
| src/utils/config.py | `configs/config.yaml`ì„ ë¶ˆëŸ¬ì™€ dataset_id, run_id, ê²½ë¡œ ë“±ì„ ê´€ë¦¬í•˜ëŠ” ì„¤ì • ìœ í‹¸ë¦¬í‹°. |
| src/utils/io.py | CSV/JSON ì…ì¶œë ¥ ë‹´ë‹¹. interim/processed ë””ë ‰í† ë¦¬ì— ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥. |
| src/utils/log.py | ì‹¤í–‰ ë¡œê·¸ ê´€ë¦¬. `logs/*.log` íŒŒì¼ë¡œ ê¸°ë¡í•´ ë””ë²„ê¹… ë° ì¶”ì  ì§€ì›. |
| src/utils/text.py | í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°. ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ í´ë¦¬ë‹, ë¬¸ìì—´ ì •ê·œí™”, í† í° í›„ì²˜ë¦¬ ë“±ì„ ì œê³µ. |


---

## 3) ë¹ ë¥¸ ì‹¤í–‰ ë°©ë²•
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt

# ìµœì‹  datasetìœ¼ë¡œ ì‹¤í–‰
python run_pipeline.py

# íŠ¹ì • dataset snapshot ì§€ì •
python run_pipeline.py --dataset_id 2025-09-23_1000
````

---

## 4) ì„¤ì •íŒŒì¼ (configs/config.yaml)

```
configs/config.yaml
- dataset.mode: `None`
- dataset.id: `None`
- dataset.raw_root: `None` (glob: `None`)
- run.run_id: `None` (ìë™: `{dataset_id}_{YYYYMMDDHHMMSS}`)
- outputs_root: `None`
- interim_root: `None`, processed_root: `None`
```

---

## 5) íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ â€” í˜„ì¬ vs ë¯¸êµ¬í˜„

| ë‹¨ê³„ íŒŒì¼                 | ìƒíƒœ / ì„¤ëª…             |
| --------------------- | ------------------- |
| `src/08_dashboard.py` | ì •ì  HTML ëŒ€ì‹œë³´ë“œ (stub) |

### ğŸš§ ê³„íšì€ ë˜ì—ˆìœ¼ë‚˜ ë¯¸êµ¬í˜„ëœ íŒŒì¼

* src/02\_tokenize\_korean.py
* src/03\_keywords\_tfidf\_true.py
* src/05\_topics\_lda.py
* src/05\_topics\_bertopic.py
* src/06\_ner\_spacy\_ko.py
* src/07\_classify\_ml.py
* src/08\_dashboard\_plotly.py
* notebooks/EDA.ipynb

---

## 6) ì¶œë ¥ë¬¼

* `data/interim/{run_id}/cleaned.csv`, `tokens.csv`
* `data/processed/{run_id}/keywords_top.csv`, `ngrams_edges.csv`, `topics.json`, `entities.csv`, `layer_tags.csv`
* `outputs/runs/{run_id}/dashboard/dash.html`
* `outputs/latest_run.json`

---

## 7) ìš”êµ¬ ì‚¬í•­ (ìš”ì•½)

* pandas, numpy, PyYAML, tqdm, scikit-learn, networkx, matplotlib, plotly

---

## 8) ë¡œë“œë§µ

* ğŸ”¤ í† í°í™” â†’ `kiwipiepy` / `OKT` ì ìš© (í’ˆì‚¬ í•„í„°ë§, ë³µí•©ëª…ì‚¬ ì²˜ë¦¬)
* ğŸ—ï¸ í‚¤ì›Œë“œ â†’ TF-IDF (scikit-learn)
* ğŸ“‘ í† í”½ â†’ LDA + coherence / BERTopic (ë‹¤êµ­ì–´ ì§€ì›)
* ğŸ§© NER â†’ spaCy Ko/KoELECTRA ê¸°ë°˜
* ğŸ·ï¸ ë¶„ë¥˜ê¸° â†’ ML ê¸°ë°˜ ì •êµí™”
* ğŸ“Š ëŒ€ì‹œë³´ë“œ â†’ Plotly ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™”

---

## 9) ë¼ì´ì„ ìŠ¤

MIT (ìƒì„¸ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ ì°¸ê³ )


---

# TODO ë¦¬ìŠ¤íŠ¸: feat/tfidf-keywords

## 1. ë¸Œëœì¹˜ ìƒì„±

```bash
git checkout -b feat/tfidf-keywords
```

## 2. ì½”ë“œ ë³€ê²½ ëŒ€ìƒ

### src/03\_keywords\_tfidf.py

* [ ] ê¸°ì¡´ placeholder(ë‹¨ìˆœ ë¹ˆë„ ê¸°ë°˜) ì½”ë“œë¥¼ scikit-learn `TfidfVectorizer` ê¸°ë°˜ìœ¼ë¡œ êµì²´
* [ ] ì…ë ¥: `tokens.csv`
* [ ] ì²˜ë¦¬: ë¬¸ì„œë³„ TF-IDF ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚° â†’ ìƒìœ„ nê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
* [ ] ì¶œë ¥: `keywords_top.csv` (`term, score, doc_id`)

## 3. utils í™•ì¥

### src/utils/text.py

* [ ] ì„ íƒì ìœ¼ë¡œ `normalize_tokens()` í•¨ìˆ˜ ë³´ê°•: ë¶ˆìš©ì–´ ì œê±° ë° ë™ì˜ì–´ ì¹˜í™˜ í›„ TF-IDF ì ìš© ê°€ëŠ¥í•˜ë„ë¡ ì „ì²˜ë¦¬ ê°•í™”

## 4. ì„¤ì • í™•ì¥

### configs/config.yaml

* [ ] keywords ì„¹ì…˜ ì¶”ê°€

```yaml
keywords:
  top_n: 20
  min_df: 2
  max_df: 0.8
```

* [ ] min\_df, max\_df ê°’ì„ ì ìš©í•´ í¬ê·€ ë‹¨ì–´ë‚˜ ë„ˆë¬´ í”í•œ ë‹¨ì–´ë¥¼ í•„í„°ë§

## 5. ì¶œë ¥ ê²€ì¦

* [ ] ê²°ê³¼ë¬¼(`data/processed/{run_id}/keywords_top.csv`) í™•ì¸

  * ì»¬ëŸ¼: `doc_id, keyword, tfidf_score`
* [ ] READMEì— ìƒ˜í”Œ ì¶œë ¥ ì˜ˆì‹œ ì¶”ê°€

## 6. ë¡œê·¸ ë³´ê°•

### src/utils/log.py

* [ ] TF-IDF ë§¤íŠ¸ë¦­ìŠ¤ í¬ê¸°ì™€ top\_n í‚¤ì›Œë“œ ì •ë³´ë¥¼ ë¡œê·¸ë¡œ ì¶œë ¥
* ë¡œê·¸ ì˜ˆì‹œ

```
[INFO] TF-IDF matrix shape: (120 docs, 5400 terms)
[INFO] Top 20 keywords per doc written to processed/...
```

## 7. í…ŒìŠ¤íŠ¸ ë° í‘¸ì‹œ

```bash
python run_pipeline.py --dataset_id News_raw_data
git add .
git commit -m "feat: implement TF-IDF keyword extraction"
git push -u origin feat/tfidf-keywords
```

## ìš”ì•½

* í•µì‹¬ êµ¬í˜„: `03_keywords_tfidf.py`ë¥¼ TF-IDF ê¸°ë°˜ìœ¼ë¡œ êµì²´
* ë³´ì¡° ìˆ˜ì •: `text.py`, `config.yaml`, `log.py` í™•ì¥
* ì‚°ì¶œë¬¼: `keywords_top.csv` â†’ TF-IDF ìƒìœ„ í‚¤ì›Œë“œ
* Copilot í™œìš© í¬ì¸íŠ¸: TODO ì£¼ì„, í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ íŒíŠ¸, ì„¤ì •ê°’ ì˜ˆì‹œ






